{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating 1-r map**\n",
    "- Allows for more straightforward visualization of the brain map\n",
    "- Masked: brain_maps/gsp1000MF_vs_yeo1000_precomputed_avgR-1-r_masked.nii.gz\n",
    "- Unmasked: brain_maps/gsp1000MF_vs_yeo1000_precomputed_avgR-1-r_dil.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nimlab.jax_functions import NiftiMasker\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "map_path = 'brain_maps/gsp1000MF_vs_yeo1000_precomputed_avgr.nii.gz'\n",
    "masker = NiftiMasker('MNI152_T1_2mm_brain_mask')\n",
    "data = masker.transform(map_path)\n",
    "data = 1-data\n",
    "new_map = masker.inverse_transform(data)\n",
    "new_map.to_filename('brain_maps/gsp1000MF_vs_yeo1000_precomputed_avgR-1-r_masked.nii.gz')\n",
    "\n",
    "masker = NiftiMasker('MNI152_T1_2mm_brain_mask_dil')\n",
    "data = masker.transform(map_path)\n",
    "data = 1-data\n",
    "new_map = masker.inverse_transform(data)\n",
    "new_map.to_filename('brain_maps/gsp1000MF_vs_yeo1000_precomputed_avgR-1-r_dil.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create 1-r map for gsp803/yeo803 differences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nimlab.jax_functions import NiftiMasker\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "map_path = 'brain_maps/gsp803_vs_yeo803_precomputed_avgr.nii.gz'\n",
    "masker = NiftiMasker('MNI152_T1_2mm_brain_mask')\n",
    "data = masker.transform(map_path)\n",
    "data = 1-data\n",
    "new_map = masker.inverse_transform(data)\n",
    "new_map.to_filename('brain_maps/gsp803_vs_yeo803_precomputed_avgr_avgR-1-r_masked.nii.gz')\n",
    "\n",
    "masker = NiftiMasker('MNI152_T1_2mm_brain_mask_dil')\n",
    "data = masker.transform(map_path)\n",
    "data = 1-data\n",
    "new_map = masker.inverse_transform(data)\n",
    "new_map.to_filename('brain_maps/gsp803_vs_yeo803_precomputed_avgr-1-r_dil.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating ROI of voxels with highest 1-r values** (highest disagreement between connectomes) in brainstem.\n",
    "We are interested in voxels with r less than .90, that are in brainstem/cerebellum.\n",
    "We will generate three ROIs:\n",
    "- Values with r < .90 within the brain itself (rois/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz)\n",
    "- Values with r < .90 within the dilated mask (rois/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz)\n",
    "- Values with r < .90 within the dilated mask but outside the brain (csf) (rois/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_csf_roi.nii.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nimlab.jax_functions import NiftiMasker, load_image, load_mask\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "# Masked ROI generation\n",
    "map_path = 'brain_maps/gsp1000MF_vs_yeo1000_precomputed_avgR-1-r_masked.nii.gz'\n",
    "map_data = load_image(map_path).get_fdata()\n",
    "\n",
    "# Exclude anything in map_image superior to MNI z=-32 (in array space, anything above 20)\n",
    "map_data[:, :, 20:] = 0\n",
    "# Exclude anything in map_image anterior to y=-34 (in array space, anything above 46)\n",
    "map_data[:, 46:, :] = 0\n",
    "\n",
    "# Threshold and binarize at 0.1\n",
    "map_data[map_data < 0.1] = 0\n",
    "map_data[map_data >= 0.1] = 1\n",
    "\n",
    "masker = NiftiMasker('MNI152_T1_2mm_brain_mask')\n",
    "new_image = masker.inverse_transform(masker.transform(load_image(map_data)))\n",
    "\n",
    "new_image.to_filename('rois/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz')\n",
    "\n",
    "\n",
    "# Dilated ROI generation\n",
    "map_path = 'brain_maps/gsp1000MF_vs_yeo1000_precomputed_avgR-1-r_dil.nii.gz'\n",
    "map_data = load_image(map_path).get_fdata()\n",
    "\n",
    "# Exclude anything in map_image superior to MNI z=-32 (in array space, anything above 20)\n",
    "map_data[:, :, 20:] = 0\n",
    "# Exclude anything in map_image anterior to y=-34 (in array space, anything above 46)\n",
    "map_data[:, 46:, :] = 0\n",
    "\n",
    "# Threshold and binarize at 0.1\n",
    "map_data[map_data < 0.1] = 0\n",
    "map_data[map_data >= 0.1] = 1\n",
    "\n",
    "masker = NiftiMasker('MNI152_T1_2mm_brain_mask_dil')\n",
    "new_image = masker.inverse_transform(masker.transform(load_image(map_data)))\n",
    "\n",
    "new_image.to_filename('rois/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz')\n",
    "\n",
    "# Find the voxels in the dilated ROI that are not in the masked ROI\n",
    "dilated_roi = masker.transform('rois/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz')\n",
    "masked_roi = masker.transform('rois/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz')\n",
    "diff_roi = dilated_roi - masked_roi\n",
    "diff_roi_image = masker.inverse_transform(diff_roi)\n",
    "diff_roi_image.to_filename('rois/1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sampling spheres from the ROIs**\n",
    "- We are going to make 15 spheres of 2mm radius across the discrepant voxels.\n",
    "- 10 from the brain, 5 from the CSF\n",
    "- We will save the coordinates and paths to the spheres in csvs/sphere_coords.csv\n",
    "- The spheres will be saved in /rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, plotting\n",
    "from nimlab.jax_functions import load_mask, load_image\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "def make_sphere(coord, brain_mask, radius, voxel_coord = False):\n",
    "    #Transform from MNI coordinates to voxelwise(matrix) coords\n",
    "    if voxel_coord == False:\n",
    "        inv_affine = inv(brain_mask.affine)\n",
    "        \n",
    "        trans_raw_coord = image.coord_transform(coord[0], coord[1], coord[2], inv_affine)\n",
    "        trans_coord = round(trans_raw_coord[0]), round(trans_raw_coord[1]), round(trans_raw_coord[2])\n",
    "\n",
    "    else:\n",
    "        trans_coord = coord\n",
    "\n",
    "    bin_sphere = create_bin_sphere(brain_mask.shape, trans_coord, radius)\n",
    "    sphere_img = image.new_img_like(brain_mask, bin_sphere)\n",
    "    return sphere_img\n",
    "\n",
    "def create_bin_sphere(arr_size, center, r):\n",
    "    # https://stackoverflow.com/questions/53326570/how-to-create-sphere-inside-a-ndarray-python?noredirect=1&lq=1\n",
    "    coords = np.ogrid[:arr_size[0], :arr_size[1], :arr_size[2]]\n",
    "    distance = np.sqrt((coords[0] - center[0])**2 + (coords[1]-center[1])**2 + (coords[2]-center[2])**2) \n",
    "    return 1*(distance <= r)\n",
    "\n",
    "def save_sphere(coord):\n",
    "    mask = load_mask('MNI152_T1_2mm_brain_mask_dil')\n",
    "    sphere_img = make_sphere(coord, mask, 2)\n",
    "    filename = f'rois/sphere_{coord[0]}_{coord[1]}_{coord[2]}.nii.gz'\n",
    "    sphere_img.to_filename(filename)\n",
    "    return filename\n",
    "\n",
    "# Load the masked ROI\n",
    "masked_roi = load_image('rois/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz')\n",
    "masked_roi_data = masked_roi.get_fdata()\n",
    "\n",
    "# Load the CSF ROI\n",
    "csf_roi = load_image('rois/1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi.nii.gz')\n",
    "csf_roi_data = csf_roi.get_fdata()\n",
    "\n",
    "# Now, we want to randomly select the indices of 10 voxels in the masked ROI where the value is 1\n",
    "masked_roi_indices = np.argwhere(masked_roi_data == 1)\n",
    "np.random.shuffle(masked_roi_indices)\n",
    "masked_roi_indices = masked_roi_indices[:20]\n",
    "\n",
    "# We want to do the same thing with the CSF ROI, but only 5 voxels\n",
    "csf_roi_indices = np.argwhere(csf_roi_data == 1)\n",
    "np.random.shuffle(csf_roi_indices)\n",
    "csf_roi_indices = csf_roi_indices[:10]\n",
    "\n",
    "# Create lists to hold the data\n",
    "brain_data = []\n",
    "csf_data = []\n",
    "\n",
    "# Add brain data to the list\n",
    "for i in range(20):\n",
    "    mni_coord = image.coord_transform(masked_roi_indices[i][0], masked_roi_indices[i][1], masked_roi_indices[i][2], masked_roi.affine)\n",
    "    mni_coord = round(mni_coord[0]), round(mni_coord[1]), round(mni_coord[2])\n",
    "    brain_data.append({'region_type': 'brain', 'voxel_coord': tuple(masked_roi_indices[i]), 'mni_coord': mni_coord})\n",
    "\n",
    "# Add CSF data to the list\n",
    "for i in range(10):\n",
    "    mni_coord = image.coord_transform(csf_roi_indices[i][0], csf_roi_indices[i][1], csf_roi_indices[i][2], csf_roi.affine)\n",
    "    mni_coord = round(mni_coord[0]), round(mni_coord[1]), round(mni_coord[2])\n",
    "    csf_data.append({'region_type': 'csf', 'voxel_coord': tuple(csf_roi_indices[i]), 'mni_coord': mni_coord})\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "brain_df = pd.DataFrame(brain_data)\n",
    "csf_df = pd.DataFrame(csf_data)\n",
    "df = pd.concat([brain_df, csf_df], ignore_index=True)\n",
    "\n",
    "df['sphere_path'] = df['mni_coord'].apply(save_sphere)\n",
    "df.to_csv('csvs/sphere_coords.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just plot a sphere using nilearn to see if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, plotting\n",
    "from nimlab.jax_functions import load_mask, load_image\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "df = pd.read_csv('csvs/sphere_coords.csv')\n",
    "sphere_path = df.loc[0, 'sphere_path']\n",
    "plotting.plot_roi(sphere_path, title = '5mm sphere around MNI (0,-44,-58)', display_mode='ortho', cut_coords=[0, -44, -58], cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the GSP1000_MF Networks for each sphere using precomputed connectome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nilearn import image, plotting\n",
    "# from nimlab.jax_functions import load_mask, load_image\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv('csvs/sphere_coords.csv')\n",
    "\n",
    "if 't' not in df.columns:\n",
    "    df['t'] = 'None'\n",
    "    \n",
    "# Function to ensure the directory exists and to construct the output path correctly\n",
    "def create_output_path(connectome_name):\n",
    "    connectivity_dir = os.path.abspath(f\"{connectome_name}_networks\")\n",
    "    if not os.path.exists(connectivity_dir):\n",
    "        os.makedirs(connectivity_dir)\n",
    "    return connectivity_dir\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "connectome_name = \"GSP1000_MF\"\n",
    "for i, row in df.iterrows():\n",
    "    roi = row['sphere_path']    \n",
    "    # Create the output path\n",
    "    output_path = create_output_path(connectome_name)\n",
    "    hypothetical_path = os.path.abspath(os.path.join(output_path, os.path.basename(f'{roi.replace(\".nii.gz\",\"\")}_Precom_T.nii.gz')))\n",
    "    df.at[i, 't'] = hypothetical_path\n",
    "    df.at[i, 'sphere_path'] = os.path.abspath(roi)\n",
    "    if os.path.exists(hypothetical_path):\n",
    "        print(f\"Skipping {hypothetical_path} because it already exists.\")\n",
    "        continue\n",
    "    \n",
    "    # Construct the system command\n",
    "    command = f'connectome_precomputed -r {os.path.dirname(roi)} -c eris-{connectome_name} -o {output_path}'\n",
    "    \n",
    "    # Print the command for debugging purposes\n",
    "    print(f'Executing command: {command}')\n",
    "    \n",
    "    # Execute the command\n",
    "    os.system(command)\n",
    "    \n",
    "    # Check if the output file is being created correctly\n",
    "    if not os.path.exists(output_path):\n",
    "        print(f\"Error: The expected output file {output_path} was not created.\")\n",
    "\n",
    "df.to_csv('csvs/sphere_coords.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Yeo1000_dil networks for each sphere using precomputed connectome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nilearn import image, plotting\n",
    "# from nimlab.jax_functions import load_mask, load_image\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv('csvs/sphere_coords.csv')\n",
    "\n",
    "if 't' not in df.columns:\n",
    "    df['t'] = 'None'\n",
    "    \n",
    "# Function to ensure the directory exists and to construct the output path correctly\n",
    "def create_output_path(connectome_name):\n",
    "    connectivity_dir = os.path.abspath(f\"{connectome_name}_networks\")\n",
    "    if not os.path.exists(connectivity_dir):\n",
    "        os.makedirs(connectivity_dir)\n",
    "    return connectivity_dir\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "connectome_name = \"yeo1000_dil\"\n",
    "for i, row in df.iterrows():\n",
    "    roi = row['sphere_path']    \n",
    "    # Create the output path\n",
    "    output_path = create_output_path(connectome_name)\n",
    "    hypothetical_path = os.path.abspath(os.path.join(output_path, os.path.basename(f'{roi.replace(\".nii.gz\",\"\")}_Precom_T.nii.gz')))\n",
    "    df.at[i, 't'] = hypothetical_path\n",
    "    df.at[i, 'sphere_path'] = os.path.abspath(roi)\n",
    "    if os.path.exists(hypothetical_path):\n",
    "        print(f\"Skipping {hypothetical_path} because it already exists.\")\n",
    "        continue\n",
    "    \n",
    "    # Construct the system command\n",
    "    command = f'connectome_precomputed -r {os.path.dirname(roi)} -c eris-{connectome_name} -o {output_path}'\n",
    "    \n",
    "    # Print the command for debugging purposes\n",
    "    print(f'Executing command: {command}')\n",
    "    \n",
    "    # Execute the command\n",
    "    os.system(command)\n",
    "    \n",
    "    # Check if the output file is being created correctly\n",
    "    if not os.path.exists(output_path):\n",
    "        print(f\"Error: The expected output file {output_path} was not created.\")\n",
    "\n",
    "df.to_csv('csvs/sphere_coords.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate the network maps for the larger ROIs using regular connectome, not the precomputed connectome (GSP1000_MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "from nimlab import connectomics as cs\n",
    "from nimlab.connectomics import ConnectomeSubject, calculate_maps\n",
    "from nilearn.input_data import NiftiMasker\n",
    "# from nimlab.jax_functions import NiftiMasker\n",
    "from multiprocessing import Pool, Queue, Process\n",
    "from collections import OrderedDict\n",
    "from scipy.stats import ttest_1samp\n",
    "from nimlab import datasets as ds\n",
    "from scipy import stats\n",
    "from numba import jit\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "\n",
    "def generate_t_maps(\n",
    "    cs_roi,\n",
    "    cs_brain,\n",
    "    roi_list,\n",
    "    roi_connectome_type='volume',\n",
    "    brain_connectome_type='volume',\n",
    "    same_connectome=False,\n",
    "    warning_flag=True,\n",
    "    num_workers=4,\n",
    "    output_folder='/path/to/output/folder',\n",
    "    ind_file_output=\"\",\n",
    "    single_connectome_subject=False\n",
    "):\n",
    "    # Create ConnectomeSubject objects\n",
    "    subjects = create_connectome_subjects(\n",
    "        cs_roi, cs_brain, roi_list, [], roi_connectome_type, brain_connectome_type, same_connectome, warning_flag\n",
    "    )\n",
    "\n",
    "    # Calculate AvgR_Fz, AvgR, and T maps\n",
    "    avgR_fz_maps, avgR_maps, T_maps = calculate_maps(\n",
    "        subjects, num_workers, output_folder, ind_file_output, single_connectome_subject\n",
    "    )\n",
    "\n",
    "    return avgR_fz_maps, avgR_maps, T_maps\n",
    "\n",
    "\n",
    "def create_connectome_subjects(cs_roi, cs_brain, roi_list, masker_list, roi_connectome_type, brain_connectome_type, same_connectome, warning_flag):\n",
    "    # Load paths to all ROI connectome files\n",
    "    roi_connectome_files_norms = natsorted(glob(os.path.join(cs_roi, \"*_norms.npy\")))\n",
    "    roi_connectome_files = [\n",
    "        (glob(f.split(\"_norms\")[0] + \".npy\")[0], f) for f in roi_connectome_files_norms\n",
    "    ]\n",
    "\n",
    "    # Load paths to all Brain connectome files\n",
    "    brain_connectome_files_norms = natsorted(glob(os.path.join(cs_brain, \"*_norms.npy\")))\n",
    "    brain_connectome_files = [\n",
    "        (glob(f.split(\"_norms\")[0] + \".npy\")[0], f)\n",
    "        for f in brain_connectome_files_norms\n",
    "    ]\n",
    "\n",
    "    # Create ConnectomeSubject objects\n",
    "    subjects = []\n",
    "    for roi_connectome_file, brain_connectome_file in zip(roi_connectome_files, brain_connectome_files):\n",
    "        subject = ConnectomeSubject(\n",
    "            roi_connectome_file,\n",
    "            brain_connectome_file,\n",
    "            roi_list,\n",
    "            roi_connectome_type,\n",
    "            brain_connectome_type,\n",
    "            same_connectome,\n",
    "            warning_flag\n",
    "        )\n",
    "        subjects.append(subject)\n",
    "    \n",
    "    return subjects\n",
    "\n",
    "cs_roi = '/data/nimlab/connectome_npy/GSP1000_MF'\n",
    "cs_brain = '/data/nimlab/connectome_npy/GSP1000_MF'\n",
    "roi_connectome_type = 'volume'\n",
    "brain_connectome_type = 'volume'\n",
    "same_connectome = False\n",
    "warning_flag = True\n",
    "num_workers = 4\n",
    "output_folder = '/PHShome/jt041/projects/connectome_differences/GSP1000_MF_networks'\n",
    "ind_file_output = \"\"\n",
    "single_connectome_subject = False\n",
    "mask = ds.get_img(\"MNI152_T1_2mm_brain_mask_dil\")\n",
    "\n",
    "roi_filename_dict = {\n",
    "    0: 'rois/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz',\n",
    "    1: 'rois/1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi.nii.gz',\n",
    "    2: 'rois/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz',\n",
    "    3: 'rois/MRT_bilateral.nii.gz',\n",
    "    4: 'rois/VSM_bilateral.nii.gz',\n",
    "}\n",
    "\n",
    "roi_list = {\n",
    "    0: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi.nii.gz')),\n",
    "    1: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz')),\n",
    "    2: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz')),\n",
    "    3: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/MRT_bilateral.nii.gz')),\n",
    "    4: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/VSM_bilateral.nii.gz')),\n",
    "}\n",
    "\n",
    "avgR_fz_maps, avgR_maps, T_maps = generate_t_maps(\n",
    "    cs_roi, cs_brain, roi_list, roi_connectome_type, brain_connectome_type, same_connectome, warning_flag, num_workers, output_folder, ind_file_output, single_connectome_subject\n",
    ")\n",
    "\n",
    "roi_filename_dict = {\n",
    "    0: 'GSP1000_MF_networks/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz',\n",
    "    1: 'GSP1000_MF_networks/1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi.nii.gz',\n",
    "    2: 'GSP1000_MF_networks/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz',\n",
    "    3: 'GSP1000_MF_networks/MRT_bilateral.nii.gz',\n",
    "    4: 'GSP1000_MF_networks/VSM_bilateral.nii.gz',\n",
    "}\n",
    "\n",
    "for i in range(len(T_maps)):\n",
    "    masker = NiftiMasker(mask).fit()\n",
    "    t_map = masker.inverse_transform(T_maps[i])\n",
    "    filename = roi_filename_dict[i].replace('.nii.gz', '_T.nii.gz')\n",
    "    t_map.to_filename(os.path.abspath(filename))\n",
    "\n",
    "for i in range(len(avgR_maps)):\n",
    "    masker = NiftiMasker(mask).fit()\n",
    "    avgR_map = masker.inverse_transform(avgR_maps[i])\n",
    "    filename = roi_filename_dict[i].replace('.nii.gz', '_AvgR.nii.gz')\n",
    "    avgR_map.to_filename(os.path.abspath(filename))\n",
    "\n",
    "for i in range(len(avgR_fz_maps)):\n",
    "    masker = NiftiMasker(mask).fit()\n",
    "    avgR_fz_map = masker.inverse_transform(avgR_fz_maps[i])\n",
    "    filename = roi_filename_dict[i].replace('.nii.gz', '_AvgR_Fz.nii.gz')\n",
    "    avgR_fz_map.to_filename(os.path.abspath(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate the network maps for the larger ROIs using regular connectome, not the precomputed connectome (Yeo1000_dil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "from nimlab import connectomics as cs\n",
    "from nimlab.connectomics import ConnectomeSubject, calculate_maps\n",
    "from nilearn.input_data import NiftiMasker\n",
    "# from nimlab.jax_functions import NiftiMasker\n",
    "from multiprocessing import Pool, Queue, Process\n",
    "from collections import OrderedDict\n",
    "from scipy.stats import ttest_1samp\n",
    "from nimlab import datasets as ds\n",
    "from scipy import stats\n",
    "from numba import jit\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "\n",
    "def generate_t_maps(\n",
    "    cs_roi,\n",
    "    cs_brain,\n",
    "    roi_list,\n",
    "    roi_connectome_type='volume',\n",
    "    brain_connectome_type='volume',\n",
    "    same_connectome=False,\n",
    "    warning_flag=True,\n",
    "    num_workers=4,\n",
    "    output_folder='/path/to/output/folder',\n",
    "    ind_file_output=\"\",\n",
    "    single_connectome_subject=False\n",
    "):\n",
    "    # Create ConnectomeSubject objects\n",
    "    subjects = create_connectome_subjects(\n",
    "        cs_roi, cs_brain, roi_list, [], roi_connectome_type, brain_connectome_type, same_connectome, warning_flag\n",
    "    )\n",
    "\n",
    "    # Calculate AvgR_Fz, AvgR, and T maps\n",
    "    avgR_fz_maps, avgR_maps, T_maps = calculate_maps(\n",
    "        subjects, num_workers, output_folder, ind_file_output, single_connectome_subject\n",
    "    )\n",
    "\n",
    "    return avgR_fz_maps, avgR_maps, T_maps\n",
    "\n",
    "\n",
    "def create_connectome_subjects(cs_roi, cs_brain, roi_list, masker_list, roi_connectome_type, brain_connectome_type, same_connectome, warning_flag):\n",
    "    # Load paths to all ROI connectome files\n",
    "    roi_connectome_files_norms = natsorted(glob(os.path.join(cs_roi, \"*_norms.npy\")))\n",
    "    roi_connectome_files = [\n",
    "        (glob(f.split(\"_norms\")[0] + \".npy\")[0], f) for f in roi_connectome_files_norms\n",
    "    ]\n",
    "\n",
    "    # Load paths to all Brain connectome files\n",
    "    brain_connectome_files_norms = natsorted(glob(os.path.join(cs_brain, \"*_norms.npy\")))\n",
    "    brain_connectome_files = [\n",
    "        (glob(f.split(\"_norms\")[0] + \".npy\")[0], f)\n",
    "        for f in brain_connectome_files_norms\n",
    "    ]\n",
    "\n",
    "    # Create ConnectomeSubject objects\n",
    "    subjects = []\n",
    "    for roi_connectome_file, brain_connectome_file in zip(roi_connectome_files, brain_connectome_files):\n",
    "        subject = ConnectomeSubject(\n",
    "            roi_connectome_file,\n",
    "            brain_connectome_file,\n",
    "            roi_list,\n",
    "            roi_connectome_type,\n",
    "            brain_connectome_type,\n",
    "            same_connectome,\n",
    "            warning_flag\n",
    "        )\n",
    "        subjects.append(subject)\n",
    "    \n",
    "    return subjects\n",
    "\n",
    "cs_roi = '/data/nimlab/connectome_npy/yeo1000_dil'\n",
    "cs_brain = '/data/nimlab/connectome_npy/yeo1000_dil'\n",
    "roi_connectome_type = 'volume'\n",
    "brain_connectome_type = 'volume'\n",
    "same_connectome = False\n",
    "warning_flag = True\n",
    "num_workers = 4\n",
    "output_folder = '/PHShome/jt041/projects/connectome_differences/yeo1000_dil_networks'\n",
    "ind_file_output = \"\"\n",
    "single_connectome_subject = False\n",
    "mask = ds.get_img(\"MNI152_T1_2mm_brain_mask_dil\")\n",
    "\n",
    "roi_filename_dict = {\n",
    "    0: 'rois/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz',\n",
    "    1: 'rois/1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi.nii.gz',\n",
    "    2: 'rois/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz',\n",
    "    3: 'rois/MRT_bilateral.nii.gz',\n",
    "    4: 'rois/VSM_bilateral.nii.gz',\n",
    "}\n",
    "\n",
    "roi_list = {\n",
    "    0: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi.nii.gz')),\n",
    "    1: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz')),\n",
    "    2: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz')),\n",
    "    3: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/MRT_bilateral.nii.gz')),\n",
    "    4: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/VSM_bilateral.nii.gz')),\n",
    "}\n",
    "\n",
    "avgR_fz_maps, avgR_maps, T_maps = generate_t_maps(\n",
    "    cs_roi, cs_brain, roi_list, roi_connectome_type, brain_connectome_type, same_connectome, warning_flag, num_workers, output_folder, ind_file_output, single_connectome_subject\n",
    ")\n",
    "\n",
    "roi_filename_dict = {\n",
    "    0: 'yeo1000_dil_networks/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz',\n",
    "    1: 'yeo1000_dil_networks/1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi.nii.gz',\n",
    "    2: 'yeo1000_dil_networks/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz',\n",
    "    3: 'yeo1000_dil_networks/MRT_bilateral.nii.gz',\n",
    "    4: 'yeo1000_dil_networks/VSM_bilateral.nii.gz',\n",
    "}\n",
    "\n",
    "for i in range(len(T_maps)):\n",
    "    masker = NiftiMasker(mask).fit()\n",
    "    t_map = masker.inverse_transform(T_maps[i])\n",
    "    filename = roi_filename_dict[i].replace('.nii.gz', '_T.nii.gz')\n",
    "    t_map.to_filename(os.path.abspath(filename))\n",
    "\n",
    "for i in range(len(avgR_maps)):\n",
    "    masker = NiftiMasker(mask).fit()\n",
    "    avgR_map = masker.inverse_transform(avgR_maps[i])\n",
    "    filename = roi_filename_dict[i].replace('.nii.gz', '_AvgR.nii.gz')\n",
    "    avgR_map.to_filename(os.path.abspath(filename))\n",
    "\n",
    "for i in range(len(avgR_fz_maps)):\n",
    "    masker = NiftiMasker(mask).fit()\n",
    "    avgR_fz_map = masker.inverse_transform(avgR_fz_maps[i])\n",
    "    filename = roi_filename_dict[i].replace('.nii.gz', '_AvgR_Fz.nii.gz')\n",
    "    avgR_fz_map.to_filename(os.path.abspath(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a master csv that contains all the information for the spheres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Adjust the working directory if running from 'notebooks'\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "# Read the initial sphere coordinates CSV\n",
    "df = pd.read_csv('csvs/sphere_coords.csv')\n",
    "\n",
    "# Initialize the master dataframe\n",
    "master_df = pd.DataFrame(columns=['region_type', 'sphere', 'voxel_coord', 'mni_coord', 'roi_path', 't_gsp1000MF', 't_yeo1000_dil'])\n",
    "\n",
    "# Iterate through the initial dataframe to populate the master dataframe\n",
    "rows_list = []\n",
    "for index, row in df.iterrows():\n",
    "    region_type = row.get('region_type', 'brain')  # Default to 'brain' if not provided\n",
    "    sphere = index < 30  # First 30 rows have sphere as True, rest as False\n",
    "    voxel_coord = row.get('voxel_coord') if index < 30 else None\n",
    "    mni_coord = row.get('mni_coord') if index < 30 else None\n",
    "    roi_path = row['sphere_path']\n",
    "\n",
    "    # Construct the file paths for the t_gsp1000MF and t_yeo1000_dil columns\n",
    "    roi_basename = os.path.basename(roi_path).replace('.nii.gz', '')\n",
    "    if roi_basename in [\n",
    "        'MRT_bilateral', 'VSM_bilateral',\n",
    "        '1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi',\n",
    "        '1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi',\n",
    "        '1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi'\n",
    "    ]:\n",
    "        t_gsp1000MF_path = f'/PHShome/jt041/projects/connectome_differences/GSP1000_MF_networks/{roi_basename}_T.nii.gz'\n",
    "        t_yeo1000_dil_path = f'/PHShome/jt041/projects/connectome_differences/yeo1000_dil_networks/{roi_basename}_T.nii.gz'\n",
    "    else:\n",
    "        t_gsp1000MF_path = f'/PHShome/jt041/projects/connectome_differences/GSP1000_MF_networks/{roi_basename}_Precom_T.nii.gz'\n",
    "        t_yeo1000_dil_path = f'/PHShome/jt041/projects/connectome_differences/yeo1000_dil_networks/{roi_basename}_Precom_T.nii.gz'\n",
    "\n",
    "    # Create a dictionary for the row\n",
    "    row_dict = {\n",
    "        'region_type': region_type,\n",
    "        'sphere': sphere,\n",
    "        'voxel_coord': voxel_coord,\n",
    "        'mni_coord': mni_coord,\n",
    "        'roi_path': roi_path,\n",
    "        't_gsp1000MF': t_gsp1000MF_path,\n",
    "        't_yeo1000_dil': t_yeo1000_dil_path\n",
    "    }\n",
    "    \n",
    "    # Append the dictionary to the list of rows\n",
    "    rows_list.append(row_dict)\n",
    "\n",
    "# Concatenate the rows list into the master dataframe\n",
    "master_df = pd.concat([master_df, pd.DataFrame(rows_list)], ignore_index=True)\n",
    "\n",
    "# Optionally save the master dataframe to a new CSV file\n",
    "master_df.to_csv('csvs/full_file_list.csv', index=False)\n",
    "\n",
    "master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up the CSF mask and create some variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nimlab.jax_functions import NiftiMasker, load_mask, load_image\n",
    "import nibabel as nib\n",
    "from nilearn.image import resample_to_img\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "\n",
    "\n",
    "# Adjust the working directory if running from 'notebooks'\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "# csf_mask_path = 'masks/csf_mask.nii.gz'\n",
    "brain_mask ='MNI152_T1_2mm_brain_mask'\n",
    "# brain_mask_img = load_mask(brain_mask)\n",
    "\n",
    "# csf_img = nib.load(csf_mask_path)\n",
    "\n",
    "# # Now, resample csf_img to the brain_mask_img and save as csf_mask_2mm.nii.gz (using nearest neighbor interpolation)\n",
    "# resampled_csf_img = resample_to_img(csf_img, brain_mask_img, interpolation='nearest')\n",
    "# resampled_csf_img.to_filename('masks/csf_mask_2mm.nii.gz')\n",
    "\n",
    "brain_mask_data = load_mask(brain_mask).get_fdata()\n",
    "brain_mask_data = binary_fill_holes(brain_mask_data).astype(float)\n",
    "brain_mask_img = load_image(brain_mask_data)\n",
    "\n",
    "masker = NiftiMasker(brain_mask_img)\n",
    "\n",
    "\n",
    "csf_mask_path = 'masks/csf_mask_2mm.nii.gz'\n",
    "\n",
    "mask_data = masker.transform(csf_mask_path)\n",
    "internal_csf_img = masker.inverse_transform(mask_data)\n",
    "internal_csf_img.to_filename('masks/internal_csf_mask_2mm.nii.gz')\n",
    "\n",
    "intern_csf_img_array = internal_csf_img.get_fdata()\n",
    "\n",
    "# We're gonna chop this array into a few pieces. \n",
    "# piece A: x (anything), y (min:52), z (min:24) # We'll call this brainstem csf\n",
    "# piece B: x (anything), y (52: max), z (24:34) # We'll call this inferomedial csf\n",
    "# piece C: x (anything), y (min:52), z (24:38) # We'll call this posterior csf\n",
    "# Piece D: x (anything), y (anything), z (34:52) # We'll call this lateral ventricular csf\n",
    "\n",
    "brainstem_csf = np.zeros_like(intern_csf_img_array)\n",
    "inferomedial_csf = np.zeros_like(intern_csf_img_array)\n",
    "posterior_csf = np.zeros_like(intern_csf_img_array)\n",
    "lateral_ventricular_csf = np.zeros_like(intern_csf_img_array)\n",
    "\n",
    "brainstem_csf[:, :, 24:52] = intern_csf_img_array[:, :, 24:52]\n",
    "inferomedial_csf[:, 52:, 24:34] = intern_csf_img_array[:, 52:, 24:34]\n",
    "posterior_csf[:, :, 24:38] = intern_csf_img_array[:, :, 24:38]\n",
    "lateral_ventricular_csf[:, :, 34:52] = intern_csf_img_array[:, :, 34:52]\n",
    "\n",
    "# Save everything to a new file\n",
    "load_image(brainstem_csf).to_filename('masks/brainstem_csf_mask_2mm.nii.gz')\n",
    "load_image(inferomedial_csf).to_filename('masks/inferomedial_csf_mask_2mm.nii.gz')\n",
    "load_image(posterior_csf).to_filename('masks/posterior_csf_mask_2mm.nii.gz')\n",
    "load_image(lateral_ventricular_csf).to_filename('masks/lateral_ventricular_csf_mask_2mm.nii.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
