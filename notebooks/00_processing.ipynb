{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating 1-r map**\n",
    "- Allows for more straightforward visualization of the brain map\n",
    "- Masked: brain_maps/gsp1000MF_vs_yeo1000_precomputed_avgR-1-r_masked.nii.gz\n",
    "- Unmasked: brain_maps/gsp1000MF_vs_yeo1000_precomputed_avgR-1-r_dil.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nimlab.jax_functions import NiftiMasker\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "map_path = 'brain_maps/gsp1000MF_vs_yeo1000_precomputed_avgr.nii.gz'\n",
    "masker = NiftiMasker('MNI152_T1_2mm_brain_mask')\n",
    "data = masker.transform(map_path)\n",
    "data = 1-data\n",
    "new_map = masker.inverse_transform(data)\n",
    "new_map.to_filename('brain_maps/gsp1000MF_vs_yeo1000_precomputed_avgR-1-r_masked.nii.gz')\n",
    "\n",
    "masker = NiftiMasker('MNI152_T1_2mm_brain_mask_dil')\n",
    "data = masker.transform(map_path)\n",
    "data = 1-data\n",
    "new_map = masker.inverse_transform(data)\n",
    "new_map.to_filename('brain_maps/gsp1000MF_vs_yeo1000_precomputed_avgR-1-r_dil.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create 1-r map for gsp803/yeo803 differences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nimlab.jax_functions import NiftiMasker\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "map_path = 'brain_maps/gsp803_vs_yeo803_precomputed_avgr.nii.gz'\n",
    "masker = NiftiMasker('MNI152_T1_2mm_brain_mask')\n",
    "data = masker.transform(map_path)\n",
    "data = 1-data\n",
    "new_map = masker.inverse_transform(data)\n",
    "new_map.to_filename('brain_maps/gsp803_vs_yeo803_precomputed_avgr_avgR-1-r_masked.nii.gz')\n",
    "\n",
    "masker = NiftiMasker('MNI152_T1_2mm_brain_mask_dil')\n",
    "data = masker.transform(map_path)\n",
    "data = 1-data\n",
    "new_map = masker.inverse_transform(data)\n",
    "new_map.to_filename('brain_maps/gsp803_vs_yeo803_precomputed_avgr-1-r_dil.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating ROI of voxels with highest 1-r values** (highest disagreement between connectomes) in brainstem.\n",
    "We are interested in voxels with r less than .90, that are in brainstem/cerebellum.\n",
    "We will generate three ROIs:\n",
    "- Values with r < .90 within the brain itself (rois/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz)\n",
    "- Values with r < .90 within the dilated mask (rois/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz)\n",
    "- Values with r < .90 within the dilated mask but outside the brain (csf) (rois/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_csf_roi.nii.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nimlab.jax_functions import NiftiMasker, load_image, load_mask\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "# Masked ROI generation\n",
    "map_path = 'brain_maps/gsp1000MF_vs_yeo1000_precomputed_avgR-1-r_masked.nii.gz'\n",
    "map_data = load_image(map_path).get_fdata()\n",
    "\n",
    "# Exclude anything in map_image superior to MNI z=-32 (in array space, anything above 20)\n",
    "map_data[:, :, 20:] = 0\n",
    "# Exclude anything in map_image anterior to y=-34 (in array space, anything above 46)\n",
    "map_data[:, 46:, :] = 0\n",
    "\n",
    "# Threshold and binarize at 0.1\n",
    "map_data[map_data < 0.1] = 0\n",
    "map_data[map_data >= 0.1] = 1\n",
    "\n",
    "masker = NiftiMasker('MNI152_T1_2mm_brain_mask')\n",
    "new_image = masker.inverse_transform(masker.transform(load_image(map_data)))\n",
    "\n",
    "new_image.to_filename('rois/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz')\n",
    "\n",
    "\n",
    "# Dilated ROI generation\n",
    "map_path = 'brain_maps/gsp1000MF_vs_yeo1000_precomputed_avgR-1-r_dil.nii.gz'\n",
    "map_data = load_image(map_path).get_fdata()\n",
    "\n",
    "# Exclude anything in map_image superior to MNI z=-32 (in array space, anything above 20)\n",
    "map_data[:, :, 20:] = 0\n",
    "# Exclude anything in map_image anterior to y=-34 (in array space, anything above 46)\n",
    "map_data[:, 46:, :] = 0\n",
    "\n",
    "# Threshold and binarize at 0.1\n",
    "map_data[map_data < 0.1] = 0\n",
    "map_data[map_data >= 0.1] = 1\n",
    "\n",
    "masker = NiftiMasker('MNI152_T1_2mm_brain_mask_dil')\n",
    "new_image = masker.inverse_transform(masker.transform(load_image(map_data)))\n",
    "\n",
    "new_image.to_filename('rois/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz')\n",
    "\n",
    "# Find the voxels in the dilated ROI that are not in the masked ROI\n",
    "dilated_roi = masker.transform('rois/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz')\n",
    "masked_roi = masker.transform('rois/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz')\n",
    "diff_roi = dilated_roi - masked_roi\n",
    "diff_roi_image = masker.inverse_transform(diff_roi)\n",
    "diff_roi_image.to_filename('rois/1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sampling spheres from the ROIs**\n",
    "- We are going to make 15 spheres of 2mm radius across the discrepant voxels.\n",
    "- 10 from the brain, 5 from the CSF\n",
    "- We will save the coordinates and paths to the spheres in csvs/sphere_coords.csv\n",
    "- The spheres will be saved in /rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, plotting\n",
    "from nimlab.jax_functions import load_mask, load_image\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "def make_sphere(coord, brain_mask, radius, voxel_coord = False):\n",
    "    #Transform from MNI coordinates to voxelwise(matrix) coords\n",
    "    if voxel_coord == False:\n",
    "        inv_affine = inv(brain_mask.affine)\n",
    "        \n",
    "        trans_raw_coord = image.coord_transform(coord[0], coord[1], coord[2], inv_affine)\n",
    "        trans_coord = round(trans_raw_coord[0]), round(trans_raw_coord[1]), round(trans_raw_coord[2])\n",
    "\n",
    "    else:\n",
    "        trans_coord = coord\n",
    "\n",
    "    bin_sphere = create_bin_sphere(brain_mask.shape, trans_coord, radius)\n",
    "    sphere_img = image.new_img_like(brain_mask, bin_sphere)\n",
    "    return sphere_img\n",
    "\n",
    "def create_bin_sphere(arr_size, center, r):\n",
    "    # https://stackoverflow.com/questions/53326570/how-to-create-sphere-inside-a-ndarray-python?noredirect=1&lq=1\n",
    "    coords = np.ogrid[:arr_size[0], :arr_size[1], :arr_size[2]]\n",
    "    distance = np.sqrt((coords[0] - center[0])**2 + (coords[1]-center[1])**2 + (coords[2]-center[2])**2) \n",
    "    return 1*(distance <= r)\n",
    "\n",
    "def save_sphere(coord):\n",
    "    mask = load_mask('MNI152_T1_2mm_brain_mask_dil')\n",
    "    sphere_img = make_sphere(coord, mask, 2)\n",
    "    filename = f'rois/sphere_{coord[0]}_{coord[1]}_{coord[2]}.nii.gz'\n",
    "    sphere_img.to_filename(filename)\n",
    "    return filename\n",
    "\n",
    "# Load the masked ROI\n",
    "masked_roi = load_image('rois/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz')\n",
    "masked_roi_data = masked_roi.get_fdata()\n",
    "\n",
    "# Load the CSF ROI\n",
    "csf_roi = load_image('rois/1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi.nii.gz')\n",
    "csf_roi_data = csf_roi.get_fdata()\n",
    "\n",
    "# Now, we want to randomly select the indices of 10 voxels in the masked ROI where the value is 1\n",
    "masked_roi_indices = np.argwhere(masked_roi_data == 1)\n",
    "np.random.shuffle(masked_roi_indices)\n",
    "masked_roi_indices = masked_roi_indices[:20]\n",
    "\n",
    "# We want to do the same thing with the CSF ROI, but only 5 voxels\n",
    "csf_roi_indices = np.argwhere(csf_roi_data == 1)\n",
    "np.random.shuffle(csf_roi_indices)\n",
    "csf_roi_indices = csf_roi_indices[:10]\n",
    "\n",
    "# Create lists to hold the data\n",
    "brain_data = []\n",
    "csf_data = []\n",
    "\n",
    "# Add brain data to the list\n",
    "for i in range(20):\n",
    "    mni_coord = image.coord_transform(masked_roi_indices[i][0], masked_roi_indices[i][1], masked_roi_indices[i][2], masked_roi.affine)\n",
    "    mni_coord = round(mni_coord[0]), round(mni_coord[1]), round(mni_coord[2])\n",
    "    brain_data.append({'region_type': 'brain', 'voxel_coord': tuple(masked_roi_indices[i]), 'mni_coord': mni_coord})\n",
    "\n",
    "# Add CSF data to the list\n",
    "for i in range(10):\n",
    "    mni_coord = image.coord_transform(csf_roi_indices[i][0], csf_roi_indices[i][1], csf_roi_indices[i][2], csf_roi.affine)\n",
    "    mni_coord = round(mni_coord[0]), round(mni_coord[1]), round(mni_coord[2])\n",
    "    csf_data.append({'region_type': 'csf', 'voxel_coord': tuple(csf_roi_indices[i]), 'mni_coord': mni_coord})\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "brain_df = pd.DataFrame(brain_data)\n",
    "csf_df = pd.DataFrame(csf_data)\n",
    "df = pd.concat([brain_df, csf_df], ignore_index=True)\n",
    "\n",
    "df['sphere_path'] = df['mni_coord'].apply(save_sphere)\n",
    "df.to_csv('csvs/sphere_coords.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just plot a sphere using nilearn to see if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, plotting\n",
    "from nimlab.jax_functions import load_mask, load_image\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "df = pd.read_csv('csvs/sphere_coords.csv')\n",
    "sphere_path = df.loc[0, 'sphere_path']\n",
    "plotting.plot_roi(sphere_path, title = '5mm sphere around MNI (0,-44,-58)', display_mode='ortho', cut_coords=[0, -44, -58], cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the GSP1000_MF Networks for each sphere using precomputed connectome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nilearn import image, plotting\n",
    "# from nimlab.jax_functions import load_mask, load_image\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv('csvs/sphere_coords.csv')\n",
    "\n",
    "if 't' not in df.columns:\n",
    "    df['t'] = 'None'\n",
    "    \n",
    "# Function to ensure the directory exists and to construct the output path correctly\n",
    "def create_output_path(connectome_name):\n",
    "    connectivity_dir = os.path.abspath(f\"{connectome_name}_networks\")\n",
    "    if not os.path.exists(connectivity_dir):\n",
    "        os.makedirs(connectivity_dir)\n",
    "    return connectivity_dir\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "connectome_name = \"GSP1000_MF\"\n",
    "for i, row in df.iterrows():\n",
    "    roi = row['sphere_path']    \n",
    "    # Create the output path\n",
    "    output_path = create_output_path(connectome_name)\n",
    "    hypothetical_path = os.path.abspath(os.path.join(output_path, os.path.basename(f'{roi.replace(\".nii.gz\",\"\")}_Precom_T.nii.gz')))\n",
    "    df.at[i, 't'] = hypothetical_path\n",
    "    df.at[i, 'sphere_path'] = os.path.abspath(roi)\n",
    "    if os.path.exists(hypothetical_path):\n",
    "        print(f\"Skipping {hypothetical_path} because it already exists.\")\n",
    "        continue\n",
    "    \n",
    "    # Construct the system command\n",
    "    command = f'connectome_precomputed -r {os.path.dirname(roi)} -c eris-{connectome_name} -o {output_path}'\n",
    "    \n",
    "    # Print the command for debugging purposes\n",
    "    print(f'Executing command: {command}')\n",
    "    \n",
    "    # Execute the command\n",
    "    os.system(command)\n",
    "    \n",
    "    # Check if the output file is being created correctly\n",
    "    if not os.path.exists(output_path):\n",
    "        print(f\"Error: The expected output file {output_path} was not created.\")\n",
    "\n",
    "df.to_csv('csvs/sphere_coords.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Yeo1000_dil networks for each sphere using precomputed connectome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nilearn import image, plotting\n",
    "# from nimlab.jax_functions import load_mask, load_image\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv('csvs/sphere_coords.csv')\n",
    "\n",
    "if 't' not in df.columns:\n",
    "    df['t'] = 'None'\n",
    "    \n",
    "# Function to ensure the directory exists and to construct the output path correctly\n",
    "def create_output_path(connectome_name):\n",
    "    connectivity_dir = os.path.abspath(f\"{connectome_name}_networks\")\n",
    "    if not os.path.exists(connectivity_dir):\n",
    "        os.makedirs(connectivity_dir)\n",
    "    return connectivity_dir\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "connectome_name = \"yeo1000_dil\"\n",
    "for i, row in df.iterrows():\n",
    "    roi = row['sphere_path']    \n",
    "    # Create the output path\n",
    "    output_path = create_output_path(connectome_name)\n",
    "    hypothetical_path = os.path.abspath(os.path.join(output_path, os.path.basename(f'{roi.replace(\".nii.gz\",\"\")}_Precom_T.nii.gz')))\n",
    "    df.at[i, 't'] = hypothetical_path\n",
    "    df.at[i, 'sphere_path'] = os.path.abspath(roi)\n",
    "    if os.path.exists(hypothetical_path):\n",
    "        print(f\"Skipping {hypothetical_path} because it already exists.\")\n",
    "        continue\n",
    "    \n",
    "    # Construct the system command\n",
    "    command = f'connectome_precomputed -r {os.path.dirname(roi)} -c eris-{connectome_name} -o {output_path}'\n",
    "    \n",
    "    # Print the command for debugging purposes\n",
    "    print(f'Executing command: {command}')\n",
    "    \n",
    "    # Execute the command\n",
    "    os.system(command)\n",
    "    \n",
    "    # Check if the output file is being created correctly\n",
    "    if not os.path.exists(output_path):\n",
    "        print(f\"Error: The expected output file {output_path} was not created.\")\n",
    "\n",
    "df.to_csv('csvs/sphere_coords.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate the network maps for the larger ROIs using regular connectome, not the precomputed connectome (GSP1000_MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "from nimlab import connectomics as cs\n",
    "from nimlab.connectomics import ConnectomeSubject, calculate_maps\n",
    "from nilearn.input_data import NiftiMasker\n",
    "# from nimlab.jax_functions import NiftiMasker\n",
    "from multiprocessing import Pool, Queue, Process\n",
    "from collections import OrderedDict\n",
    "from scipy.stats import ttest_1samp\n",
    "from nimlab import datasets as ds\n",
    "from scipy import stats\n",
    "from numba import jit\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "\n",
    "def generate_t_maps(\n",
    "    cs_roi,\n",
    "    cs_brain,\n",
    "    roi_list,\n",
    "    roi_connectome_type='volume',\n",
    "    brain_connectome_type='volume',\n",
    "    same_connectome=False,\n",
    "    warning_flag=True,\n",
    "    num_workers=4,\n",
    "    output_folder='/path/to/output/folder',\n",
    "    ind_file_output=\"\",\n",
    "    single_connectome_subject=False\n",
    "):\n",
    "    # Create ConnectomeSubject objects\n",
    "    subjects = create_connectome_subjects(\n",
    "        cs_roi, cs_brain, roi_list, [], roi_connectome_type, brain_connectome_type, same_connectome, warning_flag\n",
    "    )\n",
    "\n",
    "    # Calculate AvgR_Fz, AvgR, and T maps\n",
    "    avgR_fz_maps, avgR_maps, T_maps = calculate_maps(\n",
    "        subjects, num_workers, output_folder, ind_file_output, single_connectome_subject\n",
    "    )\n",
    "\n",
    "    return avgR_fz_maps, avgR_maps, T_maps\n",
    "\n",
    "\n",
    "def create_connectome_subjects(cs_roi, cs_brain, roi_list, masker_list, roi_connectome_type, brain_connectome_type, same_connectome, warning_flag):\n",
    "    # Load paths to all ROI connectome files\n",
    "    roi_connectome_files_norms = natsorted(glob(os.path.join(cs_roi, \"*_norms.npy\")))\n",
    "    roi_connectome_files = [\n",
    "        (glob(f.split(\"_norms\")[0] + \".npy\")[0], f) for f in roi_connectome_files_norms\n",
    "    ]\n",
    "\n",
    "    # Load paths to all Brain connectome files\n",
    "    brain_connectome_files_norms = natsorted(glob(os.path.join(cs_brain, \"*_norms.npy\")))\n",
    "    brain_connectome_files = [\n",
    "        (glob(f.split(\"_norms\")[0] + \".npy\")[0], f)\n",
    "        for f in brain_connectome_files_norms\n",
    "    ]\n",
    "\n",
    "    # Create ConnectomeSubject objects\n",
    "    subjects = []\n",
    "    for roi_connectome_file, brain_connectome_file in zip(roi_connectome_files, brain_connectome_files):\n",
    "        subject = ConnectomeSubject(\n",
    "            roi_connectome_file,\n",
    "            brain_connectome_file,\n",
    "            roi_list,\n",
    "            roi_connectome_type,\n",
    "            brain_connectome_type,\n",
    "            same_connectome,\n",
    "            warning_flag\n",
    "        )\n",
    "        subjects.append(subject)\n",
    "    \n",
    "    return subjects\n",
    "\n",
    "cs_roi = '/data/nimlab/connectome_npy/GSP1000_MF'\n",
    "cs_brain = '/data/nimlab/connectome_npy/GSP1000_MF'\n",
    "roi_connectome_type = 'volume'\n",
    "brain_connectome_type = 'volume'\n",
    "same_connectome = False\n",
    "warning_flag = True\n",
    "num_workers = 4\n",
    "output_folder = '/PHShome/jt041/projects/connectome_differences/GSP1000_MF_networks'\n",
    "ind_file_output = \"\"\n",
    "single_connectome_subject = False\n",
    "mask = ds.get_img(\"MNI152_T1_2mm_brain_mask_dil\")\n",
    "\n",
    "roi_filename_dict = {\n",
    "    0: 'rois/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz',\n",
    "    1: 'rois/1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi.nii.gz',\n",
    "    2: 'rois/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz',\n",
    "    3: 'rois/MRT_bilateral.nii.gz',\n",
    "    4: 'rois/VSM_bilateral.nii.gz',\n",
    "}\n",
    "\n",
    "roi_list = {\n",
    "    0: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi.nii.gz')),\n",
    "    1: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz')),\n",
    "    2: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz')),\n",
    "    3: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/MRT_bilateral.nii.gz')),\n",
    "    4: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/VSM_bilateral.nii.gz')),\n",
    "}\n",
    "\n",
    "avgR_fz_maps, avgR_maps, T_maps = generate_t_maps(\n",
    "    cs_roi, cs_brain, roi_list, roi_connectome_type, brain_connectome_type, same_connectome, warning_flag, num_workers, output_folder, ind_file_output, single_connectome_subject\n",
    ")\n",
    "\n",
    "roi_filename_dict = {\n",
    "    0: 'GSP1000_MF_networks/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz',\n",
    "    1: 'GSP1000_MF_networks/1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi.nii.gz',\n",
    "    2: 'GSP1000_MF_networks/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz',\n",
    "    3: 'GSP1000_MF_networks/MRT_bilateral.nii.gz',\n",
    "    4: 'GSP1000_MF_networks/VSM_bilateral.nii.gz',\n",
    "}\n",
    "\n",
    "for i in range(len(T_maps)):\n",
    "    masker = NiftiMasker(mask).fit()\n",
    "    t_map = masker.inverse_transform(T_maps[i])\n",
    "    filename = roi_filename_dict[i].replace('.nii.gz', '_T.nii.gz')\n",
    "    t_map.to_filename(os.path.abspath(filename))\n",
    "\n",
    "for i in range(len(avgR_maps)):\n",
    "    masker = NiftiMasker(mask).fit()\n",
    "    avgR_map = masker.inverse_transform(avgR_maps[i])\n",
    "    filename = roi_filename_dict[i].replace('.nii.gz', '_AvgR.nii.gz')\n",
    "    avgR_map.to_filename(os.path.abspath(filename))\n",
    "\n",
    "for i in range(len(avgR_fz_maps)):\n",
    "    masker = NiftiMasker(mask).fit()\n",
    "    avgR_fz_map = masker.inverse_transform(avgR_fz_maps[i])\n",
    "    filename = roi_filename_dict[i].replace('.nii.gz', '_AvgR_Fz.nii.gz')\n",
    "    avgR_fz_map.to_filename(os.path.abspath(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate the network maps for the larger ROIs using regular connectome, not the precomputed connectome (Yeo1000_dil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "from nimlab import connectomics as cs\n",
    "from nimlab.connectomics import ConnectomeSubject, calculate_maps\n",
    "from nilearn.input_data import NiftiMasker\n",
    "# from nimlab.jax_functions import NiftiMasker\n",
    "from multiprocessing import Pool, Queue, Process\n",
    "from collections import OrderedDict\n",
    "from scipy.stats import ttest_1samp\n",
    "from nimlab import datasets as ds\n",
    "from scipy import stats\n",
    "from numba import jit\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "\n",
    "def generate_t_maps(\n",
    "    cs_roi,\n",
    "    cs_brain,\n",
    "    roi_list,\n",
    "    roi_connectome_type='volume',\n",
    "    brain_connectome_type='volume',\n",
    "    same_connectome=False,\n",
    "    warning_flag=True,\n",
    "    num_workers=4,\n",
    "    output_folder='/path/to/output/folder',\n",
    "    ind_file_output=\"\",\n",
    "    single_connectome_subject=False\n",
    "):\n",
    "    # Create ConnectomeSubject objects\n",
    "    subjects = create_connectome_subjects(\n",
    "        cs_roi, cs_brain, roi_list, [], roi_connectome_type, brain_connectome_type, same_connectome, warning_flag\n",
    "    )\n",
    "\n",
    "    # Calculate AvgR_Fz, AvgR, and T maps\n",
    "    avgR_fz_maps, avgR_maps, T_maps = calculate_maps(\n",
    "        subjects, num_workers, output_folder, ind_file_output, single_connectome_subject\n",
    "    )\n",
    "\n",
    "    return avgR_fz_maps, avgR_maps, T_maps\n",
    "\n",
    "\n",
    "def create_connectome_subjects(cs_roi, cs_brain, roi_list, masker_list, roi_connectome_type, brain_connectome_type, same_connectome, warning_flag):\n",
    "    # Load paths to all ROI connectome files\n",
    "    roi_connectome_files_norms = natsorted(glob(os.path.join(cs_roi, \"*_norms.npy\")))\n",
    "    roi_connectome_files = [\n",
    "        (glob(f.split(\"_norms\")[0] + \".npy\")[0], f) for f in roi_connectome_files_norms\n",
    "    ]\n",
    "\n",
    "    # Load paths to all Brain connectome files\n",
    "    brain_connectome_files_norms = natsorted(glob(os.path.join(cs_brain, \"*_norms.npy\")))\n",
    "    brain_connectome_files = [\n",
    "        (glob(f.split(\"_norms\")[0] + \".npy\")[0], f)\n",
    "        for f in brain_connectome_files_norms\n",
    "    ]\n",
    "\n",
    "    # Create ConnectomeSubject objects\n",
    "    subjects = []\n",
    "    for roi_connectome_file, brain_connectome_file in zip(roi_connectome_files, brain_connectome_files):\n",
    "        subject = ConnectomeSubject(\n",
    "            roi_connectome_file,\n",
    "            brain_connectome_file,\n",
    "            roi_list,\n",
    "            roi_connectome_type,\n",
    "            brain_connectome_type,\n",
    "            same_connectome,\n",
    "            warning_flag\n",
    "        )\n",
    "        subjects.append(subject)\n",
    "    \n",
    "    return subjects\n",
    "\n",
    "cs_roi = '/data/nimlab/connectome_npy/yeo1000_dil'\n",
    "cs_brain = '/data/nimlab/connectome_npy/yeo1000_dil'\n",
    "roi_connectome_type = 'volume'\n",
    "brain_connectome_type = 'volume'\n",
    "same_connectome = False\n",
    "warning_flag = True\n",
    "num_workers = 4\n",
    "output_folder = '/PHShome/jt041/projects/connectome_differences/yeo1000_dil_networks'\n",
    "ind_file_output = \"\"\n",
    "single_connectome_subject = False\n",
    "mask = ds.get_img(\"MNI152_T1_2mm_brain_mask_dil\")\n",
    "\n",
    "roi_filename_dict = {\n",
    "    0: 'rois/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz',\n",
    "    1: 'rois/1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi.nii.gz',\n",
    "    2: 'rois/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz',\n",
    "    3: 'rois/MRT_bilateral.nii.gz',\n",
    "    4: 'rois/VSM_bilateral.nii.gz',\n",
    "}\n",
    "\n",
    "roi_list = {\n",
    "    0: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi.nii.gz')),\n",
    "    1: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz')),\n",
    "    2: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz')),\n",
    "    3: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/MRT_bilateral.nii.gz')),\n",
    "    4: np.atleast_2d(NiftiMasker(mask).fit_transform('/PHShome/jt041/projects/connectome_differences/rois_2/VSM_bilateral.nii.gz')),\n",
    "}\n",
    "\n",
    "avgR_fz_maps, avgR_maps, T_maps = generate_t_maps(\n",
    "    cs_roi, cs_brain, roi_list, roi_connectome_type, brain_connectome_type, same_connectome, warning_flag, num_workers, output_folder, ind_file_output, single_connectome_subject\n",
    ")\n",
    "\n",
    "roi_filename_dict = {\n",
    "    0: 'yeo1000_dil_networks/1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi.nii.gz',\n",
    "    1: 'yeo1000_dil_networks/1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi.nii.gz',\n",
    "    2: 'yeo1000_dil_networks/1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi.nii.gz',\n",
    "    3: 'yeo1000_dil_networks/MRT_bilateral.nii.gz',\n",
    "    4: 'yeo1000_dil_networks/VSM_bilateral.nii.gz',\n",
    "}\n",
    "\n",
    "for i in range(len(T_maps)):\n",
    "    masker = NiftiMasker(mask).fit()\n",
    "    t_map = masker.inverse_transform(T_maps[i])\n",
    "    filename = roi_filename_dict[i].replace('.nii.gz', '_T.nii.gz')\n",
    "    t_map.to_filename(os.path.abspath(filename))\n",
    "\n",
    "for i in range(len(avgR_maps)):\n",
    "    masker = NiftiMasker(mask).fit()\n",
    "    avgR_map = masker.inverse_transform(avgR_maps[i])\n",
    "    filename = roi_filename_dict[i].replace('.nii.gz', '_AvgR.nii.gz')\n",
    "    avgR_map.to_filename(os.path.abspath(filename))\n",
    "\n",
    "for i in range(len(avgR_fz_maps)):\n",
    "    masker = NiftiMasker(mask).fit()\n",
    "    avgR_fz_map = masker.inverse_transform(avgR_fz_maps[i])\n",
    "    filename = roi_filename_dict[i].replace('.nii.gz', '_AvgR_Fz.nii.gz')\n",
    "    avgR_fz_map.to_filename(os.path.abspath(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a master csv that contains all the information for the spheres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Adjust the working directory if running from 'notebooks'\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "# Read the initial sphere coordinates CSV\n",
    "df = pd.read_csv('csvs/sphere_coords.csv')\n",
    "\n",
    "# Initialize the master dataframe\n",
    "master_df = pd.DataFrame(columns=['region_type', 'sphere', 'voxel_coord', 'mni_coord', 'roi_path', 't_gsp1000MF', 't_yeo1000_dil'])\n",
    "\n",
    "# Iterate through the initial dataframe to populate the master dataframe\n",
    "rows_list = []\n",
    "for index, row in df.iterrows():\n",
    "    region_type = row.get('region_type', 'brain')  # Default to 'brain' if not provided\n",
    "    sphere = index < 30  # First 30 rows have sphere as True, rest as False\n",
    "    voxel_coord = row.get('voxel_coord') if index < 30 else None\n",
    "    mni_coord = row.get('mni_coord') if index < 30 else None\n",
    "    roi_path = row['sphere_path']\n",
    "\n",
    "    # Construct the file paths for the t_gsp1000MF and t_yeo1000_dil columns\n",
    "    roi_basename = os.path.basename(roi_path).replace('.nii.gz', '')\n",
    "    if roi_basename in [\n",
    "        'MRT_bilateral', 'VSM_bilateral',\n",
    "        '1-r_01_gsp1000MF_vs_yeo1000_dil_brainstem_roi',\n",
    "        '1-r_01_gsp1000MF_vs_yeo1000_masked_brainstem_roi',\n",
    "        '1-r_01_gsp1000MF_vs_yeo1000_csf_brainstem_roi'\n",
    "    ]:\n",
    "        t_gsp1000MF_path = f'/PHShome/jt041/projects/connectome_differences/GSP1000_MF_networks/{roi_basename}_T.nii.gz'\n",
    "        t_yeo1000_dil_path = f'/PHShome/jt041/projects/connectome_differences/yeo1000_dil_networks/{roi_basename}_T.nii.gz'\n",
    "    else:\n",
    "        t_gsp1000MF_path = f'/PHShome/jt041/projects/connectome_differences/GSP1000_MF_networks/{roi_basename}_Precom_T.nii.gz'\n",
    "        t_yeo1000_dil_path = f'/PHShome/jt041/projects/connectome_differences/yeo1000_dil_networks/{roi_basename}_Precom_T.nii.gz'\n",
    "\n",
    "    # Create a dictionary for the row\n",
    "    row_dict = {\n",
    "        'region_type': region_type,\n",
    "        'sphere': sphere,\n",
    "        'voxel_coord': voxel_coord,\n",
    "        'mni_coord': mni_coord,\n",
    "        'roi_path': roi_path,\n",
    "        't_gsp1000MF': t_gsp1000MF_path,\n",
    "        't_yeo1000_dil': t_yeo1000_dil_path\n",
    "    }\n",
    "    \n",
    "    # Append the dictionary to the list of rows\n",
    "    rows_list.append(row_dict)\n",
    "\n",
    "# Concatenate the rows list into the master dataframe\n",
    "master_df = pd.concat([master_df, pd.DataFrame(rows_list)], ignore_index=True)\n",
    "\n",
    "# Optionally save the master dataframe to a new CSV file\n",
    "master_df.to_csv('csvs/full_file_list.csv', index=False)\n",
    "\n",
    "master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up the CSF mask and create some variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nimlab.jax_functions import NiftiMasker, load_mask, load_image\n",
    "import nibabel as nib\n",
    "from nilearn.image import resample_to_img\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "\n",
    "\n",
    "# Adjust the working directory if running from 'notebooks'\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "# csf_mask_path = 'masks/csf_mask.nii.gz'\n",
    "brain_mask ='MNI152_T1_2mm_brain_mask'\n",
    "# brain_mask_img = load_mask(brain_mask)\n",
    "\n",
    "# csf_img = nib.load(csf_mask_path)\n",
    "\n",
    "# # Now, resample csf_img to the brain_mask_img and save as csf_mask_2mm.nii.gz (using nearest neighbor interpolation)\n",
    "# resampled_csf_img = resample_to_img(csf_img, brain_mask_img, interpolation='nearest')\n",
    "# resampled_csf_img.to_filename('masks/csf_mask_2mm.nii.gz')\n",
    "\n",
    "brain_mask_data = load_mask(brain_mask).get_fdata()\n",
    "brain_mask_data = binary_fill_holes(brain_mask_data).astype(float)\n",
    "brain_mask_img = load_image(brain_mask_data)\n",
    "\n",
    "masker = NiftiMasker(brain_mask_img)\n",
    "\n",
    "\n",
    "csf_mask_path = 'masks/csf_mask_2mm.nii.gz'\n",
    "\n",
    "mask_data = masker.transform(csf_mask_path)\n",
    "internal_csf_img = masker.inverse_transform(mask_data)\n",
    "internal_csf_img.to_filename('masks/internal_csf_mask_2mm.nii.gz')\n",
    "\n",
    "intern_csf_img_array = internal_csf_img.get_fdata()\n",
    "\n",
    "# We're gonna chop this array into a few pieces. \n",
    "# piece A: x (anything), y (min:52), z (min:24) # We'll call this brainstem csf\n",
    "# piece B: x (anything), y (52: max), z (24:34) # We'll call this inferomedial csf\n",
    "# piece C: x (anything), y (min:52), z (24:38) # We'll call this posterior csf\n",
    "# Piece D: x (anything), y (anything), z (34:52) # We'll call this lateral ventricular csf\n",
    "\n",
    "brainstem_csf = np.zeros_like(intern_csf_img_array)\n",
    "inferomedial_csf = np.zeros_like(intern_csf_img_array)\n",
    "posterior_csf = np.zeros_like(intern_csf_img_array)\n",
    "lateral_ventricular_csf = np.zeros_like(intern_csf_img_array)\n",
    "\n",
    "brainstem_csf[:, :, 24:52] = intern_csf_img_array[:, :, 24:52]\n",
    "inferomedial_csf[:, 52:, 24:34] = intern_csf_img_array[:, 52:, 24:34]\n",
    "posterior_csf[:, :, 24:38] = intern_csf_img_array[:, :, 24:38]\n",
    "lateral_ventricular_csf[:, :, 34:52] = intern_csf_img_array[:, :, 34:52]\n",
    "\n",
    "# Save everything to a new file\n",
    "load_image(brainstem_csf).to_filename('masks/brainstem_csf_mask_2mm.nii.gz')\n",
    "load_image(inferomedial_csf).to_filename('masks/inferomedial_csf_mask_2mm.nii.gz')\n",
    "load_image(posterior_csf).to_filename('masks/posterior_csf_mask_2mm.nii.gz')\n",
    "load_image(lateral_ventricular_csf).to_filename('masks/lateral_ventricular_csf_mask_2mm.nii.gz')\n",
    "\n",
    "dilated_masker = NiftiMasker('MNI152_T1_2mm_brain_mask_dil')\n",
    "external_csf = dilated_masker.transform('masks/csf_mask_2mm.nii.gz')\n",
    "internal_csf = dilated_masker.transform('masks/internal_csf_mask_2mm.nii.gz')\n",
    "external_csf = external_csf - internal_csf\n",
    "external_csf = dilated_masker.inverse_transform(external_csf)\n",
    "\n",
    "load_image(external_csf).to_filename('masks/external_csf_mask_2mm.nii.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, let's randomly sample some voxels within each CSF mask, and save the spheres and their coordinates to a dataframe and directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/jt041/scratch/ipykernel_132568/2444916713.py:33: UserWarning: Data array used to create a new image contains 64-bit ints. This is likely due to creating the array with numpy and passing `int` as the `dtype`. Many tools such as FSL and SPM cannot deal with int64 in Nifti images, so for compatibility the data has been converted to int32.\n",
      "  sphere_img = image.new_img_like(brain_mask, bin_sphere)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sphere generation and saving complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import image\n",
    "from nimlab.jax_functions import load_mask, load_image\n",
    "from numpy.linalg import inv\n",
    "\n",
    "# Ensure we're in the correct directory\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "save_dir = \"csf_spheres_rois\"\n",
    "csf_masks = [\n",
    "    'masks/brainstem_csf_mask_2mm.nii.gz',\n",
    "    'masks/inferomedial_csf_mask_2mm.nii.gz',\n",
    "    'masks/posterior_csf_mask_2mm.nii.gz',\n",
    "    'masks/lateral_ventricular_csf_mask_2mm.nii.gz',\n",
    "    'masks/external_csf_mask_2mm.nii.gz'\n",
    "]\n",
    "\n",
    "# Create the save directory if it doesn't exist\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "def make_sphere(coord, brain_mask, radius, voxel_coord=False):\n",
    "    if not voxel_coord:\n",
    "        inv_affine = inv(brain_mask.affine)\n",
    "        trans_raw_coord = image.coord_transform(coord[0], coord[1], coord[2], inv_affine)\n",
    "        trans_coord = round(trans_raw_coord[0]), round(trans_raw_coord[1]), round(trans_raw_coord[2])\n",
    "    else:\n",
    "        trans_coord = coord\n",
    "\n",
    "    bin_sphere = create_bin_sphere(brain_mask.shape, trans_coord, radius)\n",
    "    sphere_img = image.new_img_like(brain_mask, bin_sphere)\n",
    "    return sphere_img\n",
    "\n",
    "def create_bin_sphere(arr_size, center, r):\n",
    "    coords = np.ogrid[:arr_size[0], :arr_size[1], :arr_size[2]]\n",
    "    distance = np.sqrt((coords[0] - center[0])**2 + (coords[1] - center[1])**2 + (coords[2] - center[2])**2)\n",
    "    return 1 * (distance <= r)\n",
    "\n",
    "def save_sphere(coord):\n",
    "    mask = load_mask('MNI152_T1_2mm_brain_mask_dil')\n",
    "    sphere_img = make_sphere(coord, mask, 1)\n",
    "    filename = os.path.join(save_dir, f'sphere_{coord[0]}_{coord[1]}_{coord[2]}.nii.gz')\n",
    "    sphere_img.to_filename(filename)\n",
    "    return filename\n",
    "\n",
    "# Initialize lists to hold data\n",
    "csf_data = []\n",
    "\n",
    "# Sample five spheres from each CSF mask\n",
    "for csf_mask_path in csf_masks:\n",
    "    csf_mask = load_image(csf_mask_path)\n",
    "    csf_mask_data = csf_mask.get_fdata()\n",
    "\n",
    "    # Randomly select the indices of 5 voxels in the CSF mask where the value is 1\n",
    "    csf_roi_indices = np.argwhere(csf_mask_data == 1)\n",
    "    np.random.shuffle(csf_roi_indices)\n",
    "    csf_roi_indices = csf_roi_indices[:5]\n",
    "\n",
    "    for i in range(5):\n",
    "        mni_coord = image.coord_transform(csf_roi_indices[i][0], csf_roi_indices[i][1], csf_roi_indices[i][2], csf_mask.affine)\n",
    "        mni_coord = round(mni_coord[0]), round(mni_coord[1]), round(mni_coord[2])\n",
    "        csf_data.append({'region_type': 'csf', 'voxel_coord': tuple(csf_roi_indices[i]), 'mni_coord': mni_coord})\n",
    "\n",
    "# Convert list to DataFrame\n",
    "csf_df = pd.DataFrame(csf_data)\n",
    "csf_df['sphere_path'] = csf_df['mni_coord'].apply(save_sphere)\n",
    "csf_df.to_csv('csvs/csf_sphere_coords.csv', index=False)\n",
    "\n",
    "print(\"Sphere generation and saving complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make an actually good lateral ventricle mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import image\n",
    "from nimlab.jax_functions import load_mask, load_image, NiftiMasker\n",
    "from numpy.linalg import inv\n",
    "\n",
    "# Ensure we're in the correct directory\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "masker = NiftiMasker()\n",
    "path = 'masks/HarvardOxford-sub-maxprob-thr0-2mm.nii.gz'\n",
    "data = masker.transform(path)\n",
    "# Set all values to be 0 except where the values is 3 or the value is 14\n",
    "\n",
    "# Keep same shape and all values where the value is 3 should be 1, all others 0\n",
    "left_lateral_ventricle = np.zeros_like(data)\n",
    "left_lateral_ventricle[data == 3] = 1\n",
    "\n",
    "# Keep same shape and all values where the value is 14 should be 1, all others 0\n",
    "right_lateral_ventricle = np.zeros_like(data)\n",
    "right_lateral_ventricle[data == 14] = 1\n",
    "\n",
    "left_lateral_ventricle = masker.inverse_transform(left_lateral_ventricle)\n",
    "right_lateral_ventricle = masker.inverse_transform(right_lateral_ventricle)\n",
    "\n",
    "left_lateral_ventricle.to_filename('masks/left_lateral_ventricle_mask_2mm.nii.gz')\n",
    "right_lateral_ventricle.to_filename('masks/right_lateral_ventricle_mask_2mm.nii.gz')\n",
    "\n",
    "# Now, for both of these ventricle masks, let's cut them in half along the y axis; everything ahead of y=56 will be kept, with suffix appended ('anterior').\n",
    "# Everything behind y=56 will be kept, with suffix appended ('posterior').\n",
    "\n",
    "left_lateral_ventricle_data = left_lateral_ventricle.get_fdata()\n",
    "right_lateral_ventricle_data = right_lateral_ventricle.get_fdata()\n",
    "\n",
    "left_anterior_lateral_ventricle = np.zeros_like(left_lateral_ventricle_data)\n",
    "left_posterior_lateral_ventricle = np.zeros_like(left_lateral_ventricle_data)\n",
    "\n",
    "right_anterior_lateral_ventricle = np.zeros_like(right_lateral_ventricle_data)\n",
    "right_posterior_lateral_ventricle = np.zeros_like(right_lateral_ventricle_data)\n",
    "\n",
    "left_anterior_lateral_ventricle[:, :56, :] = left_lateral_ventricle_data[:, :56, :]\n",
    "left_posterior_lateral_ventricle[:, 56:, :] = left_lateral_ventricle_data[:, 56:, :]\n",
    "\n",
    "right_anterior_lateral_ventricle[:, :56, :] = right_lateral_ventricle_data[:, :56, :]\n",
    "right_posterior_lateral_ventricle[:, 56:, :] = right_lateral_ventricle_data[:, 56:, :]\n",
    "\n",
    "left_anterior_lateral_ventricle = load_image(left_anterior_lateral_ventricle)\n",
    "left_posterior_lateral_ventricle = load_image(left_posterior_lateral_ventricle)\n",
    "\n",
    "right_anterior_lateral_ventricle = load_image(right_anterior_lateral_ventricle)\n",
    "right_posterior_lateral_ventricle = load_image(right_posterior_lateral_ventricle)\n",
    "\n",
    "left_anterior_lateral_ventricle.to_filename('masks/left_anterior_lateral_ventricle_mask_2mm.nii.gz')\n",
    "left_posterior_lateral_ventricle.to_filename('masks/left_posterior_lateral_ventricle_mask_2mm.nii.gz')\n",
    "right_anterior_lateral_ventricle.to_filename('masks/right_anterior_lateral_ventricle_mask_2mm.nii.gz')\n",
    "right_posterior_lateral_ventricle.to_filename('masks/right_posterior_lateral_ventricle_mask_2mm.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a pregenual ACC mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import image\n",
    "from nimlab.jax_functions import load_mask, load_image, NiftiMasker\n",
    "from numpy.linalg import inv\n",
    "from nilearn.image import resample_to_img, load_img\n",
    "\n",
    "# Ensure we're in the correct directory\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "path_1mm = 'masks/AAL3_1mm.nii.gz'\n",
    "img = load_img(path_1mm)\n",
    "# We only want to keep values in img where value is 149 or 150. We need to keep the same shape.\n",
    "# Where its 149 or 150, set to 1, else 0\n",
    "img_data = img.get_fdata()\n",
    "new_data = np.zeros_like(img_data)\n",
    "new_data[(img_data == 149) | (img_data == 150)] = 1\n",
    "new_img = image.new_img_like(img, new_data)\n",
    "\n",
    "mask_img = load_mask('MNI152_T1_2mm_brain_mask_dil')\n",
    "\n",
    "resampled_img = resample_to_img(new_img, mask_img, interpolation='nearest')\n",
    "resampled_img.to_filename('masks/pregenual.nii.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a subgenual ACC mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import image\n",
    "from nimlab.jax_functions import load_mask, load_image, NiftiMasker\n",
    "from numpy.linalg import inv\n",
    "from nilearn.image import resample_to_img, load_img\n",
    "\n",
    "# Ensure we're in the correct directory\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "path_1mm = 'masks/AAL3_1mm.nii.gz'\n",
    "img = load_img(path_1mm)\n",
    "# We only want to keep values in img where value is 149 or 150. We need to keep the same shape.\n",
    "# Where its 149 or 150, set to 1, else 0\n",
    "img_data = img.get_fdata()\n",
    "new_data = np.zeros_like(img_data)\n",
    "new_data[(img_data == 147) | (img_data == 148)] = 1\n",
    "new_img = image.new_img_like(img, new_data)\n",
    "\n",
    "mask_img = load_mask('MNI152_T1_2mm_brain_mask_dil')\n",
    "\n",
    "resampled_img = resample_to_img(new_img, mask_img, interpolation='nearest')\n",
    "resampled_img.to_filename('masks/subgenual.nii.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge pregenual and subgenual ACC masks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import image\n",
    "from nimlab.jax_functions import load_mask, load_image, NiftiMasker\n",
    "from numpy.linalg import inv\n",
    "from nilearn.image import resample_to_img, load_img\n",
    "\n",
    "# Ensure we're in the correct directory\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "pregenual_path = 'masks/pregenual.nii.gz'\n",
    "subgenual_path = 'masks/subgenual.nii.gz'\n",
    "\n",
    "pregenual_img = load_image(pregenual_path)\n",
    "subgenual_img = load_image(subgenual_path)\n",
    "\n",
    "pregenual_data = pregenual_img.get_fdata()\n",
    "subgenual_data = subgenual_img.get_fdata()\n",
    "\n",
    "# We want to combine these two masks into a single mask. We'll call this mask 'anterior_cingulate'\n",
    "anterior_cingulate_data = np.zeros_like(pregenual_data)\n",
    "anterior_cingulate_data[pregenual_data == 1] = 1\n",
    "anterior_cingulate_data[subgenual_data == 1] = 1\n",
    "\n",
    "anterior_cingulate_img = load_image(anterior_cingulate_data)\n",
    "anterior_cingulate_img.to_filename('masks/anterior_cingulate.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create amygdala mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import image\n",
    "from nimlab.jax_functions import load_mask, load_image, NiftiMasker\n",
    "from numpy.linalg import inv\n",
    "from nilearn.image import resample_to_img, load_img\n",
    "\n",
    "# Ensure we're in the correct directory\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "path_1mm = 'masks/AAL3_1mm.nii.gz'\n",
    "img = load_img(path_1mm)\n",
    "# We only want to keep values in img where value is 149 or 150. We need to keep the same shape.\n",
    "# Where its 149 or 150, set to 1, else 0\n",
    "img_data = img.get_fdata()\n",
    "new_data = np.zeros_like(img_data)\n",
    "new_data[(img_data == 43) | (img_data == 44)] = 1\n",
    "new_img = image.new_img_like(img, new_data)\n",
    "\n",
    "mask_img = load_mask('MNI152_T1_2mm_brain_mask_dil')\n",
    "\n",
    "resampled_img = resample_to_img(new_img, mask_img, interpolation='nearest')\n",
    "resampled_img.to_filename('masks/amygdala.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Caudate Mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import image\n",
    "from nimlab.jax_functions import load_mask, load_image, NiftiMasker\n",
    "from numpy.linalg import inv\n",
    "from nilearn.image import resample_to_img, load_img\n",
    "\n",
    "# Ensure we're in the correct directory\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "path_1mm = 'masks/AAL3_1mm.nii.gz'\n",
    "img = load_img(path_1mm)\n",
    "# We only want to keep values in img where value is 149 or 150. We need to keep the same shape.\n",
    "# Where its 149 or 150, set to 1, else 0\n",
    "img_data = img.get_fdata()\n",
    "new_data = np.zeros_like(img_data)\n",
    "new_data[(img_data == 73) | (img_data == 74)] = 1\n",
    "new_img = image.new_img_like(img, new_data)\n",
    "\n",
    "mask_img = load_mask('MNI152_T1_2mm_brain_mask_dil')\n",
    "\n",
    "resampled_img = resample_to_img(new_img, mask_img, interpolation='nearest')\n",
    "resampled_img.to_filename('masks/caudate.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check our Septum Mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "septum_path = 'masks/Ch-123_bilateral-prob25.nii.gz'\n",
    "septum_img = load_img(septum_path)\n",
    "\n",
    "# Resample it to the brain mask\n",
    "mask_img = load_mask('MNI152_T1_2mm_brain_mask_dil')\n",
    "resampled_septum_img = resample_to_img(septum_img, mask_img, interpolation='nearest')\n",
    "resampled_septum_img.to_filename('masks/septum.nii.gz')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
